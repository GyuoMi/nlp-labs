{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b03109-116c-4f2e-8eeb-18bb6b928c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First paragraph ===\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Path to the book file\n",
    "FILE_PATH = \"../harry_potter/HP1.txt\"\n",
    "CONTEXT_WINDOW_SIZE = 2\n",
    "\n",
    "# ============ STEP 1: Read only the first paragraph ============\n",
    "with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "# Split into paragraphs (assuming paragraphs are separated by two newlines)\n",
    "paragraphs = full_text.strip().split('\\n\\n')\n",
    "first_paragraph = paragraphs[0]\n",
    "\n",
    "print(\"=== First paragraph ===\")\n",
    "print(first_paragraph[:500])  # preview\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e475e1-81e8-43d0-bee0-0fcdf8e1e417",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8e1d8d-c4f4-40e2-8dba-d9e57166fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['mr', 'and', 'mrs', 'dursley', 'of', 'number', 'four', 'privet', 'drive', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', 'thank', 'you', 'very', 'much', 'they', 'were', 'the', 'last', 'people', 'youd', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', 'because', 'they', 'just', 'didnt', 'hold', 'with', 'such', 'nonsense', 'mr', 'dursley', 'was', 'the', 'director']\n"
     ]
    }
   ],
   "source": [
    "# ============ STEP 2: Clean and tokenize ============\n",
    "clean_text = first_paragraph.lower()\n",
    "punctuation_list = string.punctuation + '“”’'\n",
    "translator = str.maketrans('', '', punctuation_list)\n",
    "clean_text = clean_text.translate(translator)\n",
    "\n",
    "tokens = clean_text.split()\n",
    "print(\"Tokens:\", tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66753fb0-2cbc-4612-af39-dcfeb44f19fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mr', 'mrs', 'dursley', 'of', 'number', 'four', 'privet', 'drive', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', 'thank', 'you', 'very', 'much', 'they', 'were', 'last', 'people', 'youd', 'expect', 'to', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', 'because', 'they', 'just', 'didnt', 'hold', 'with', 'such', 'nonsense', 'mr', 'dursley', 'was', 'director', 'of', 'firm', 'called', 'grunnings']\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['the', 'is', 'will', 'be', 'a', 'only', 'can', 'their', 'now', 'and', 'at', 'it']\n",
    "\n",
    "filtered_data = []\n",
    "for word in tokens:\n",
    "    if word not in stopwords:\n",
    "        filtered_data.append(word)\n",
    "print(filtered_data[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fbb50-865e-4350-a7e7-62d76f04cabf",
   "metadata": {},
   "source": [
    "## STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627ac69b-bb35-4a14-80f2-309899cd560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['mr', 'and', 'mrs', 'dursley', 'of', 'number', 'four', 'privet', 'drive', 'were', 'proud', 'to', 'say', 'that', 'they', 'perfectly', 'normal', 'thank', 'you', 'very', 'much', 'the', 'last', 'people', 'youd', 'expect', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', 'because', 'just', 'didnt', 'hold', 'with', 'such', 'nonsense', 'was', 'director', 'a', 'firm', 'called', 'grunnings', 'which', 'made', 'drills', 'he']\n",
      "Vocab size: 6022\n",
      "Index of 'harry': 397\n"
     ]
    }
   ],
   "source": [
    "# ============ STEP 3: Build vocabulary with Unique words ============\n",
    "vocabulary = []\n",
    "seen_words = set()\n",
    "\n",
    "for word in tokens:\n",
    "    if word not in seen_words:\n",
    "        vocabulary.append(word)\n",
    "        seen_words.add(word)\n",
    "\n",
    "vocab_size = len(vocabulary)\n",
    "print(\"Vocabulary:\", vocabulary[:50])\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "\n",
    "word_to_idx = {word: i for i, word in enumerate(vocabulary)}\n",
    "idx_to_word = {i: word for i, word in enumerate(vocabulary)}\n",
    "\n",
    "# Preview\n",
    "if 'harry' in word_to_idx:\n",
    "    print(\"Index of 'harry':\", word_to_idx['harry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077eb7b-15e9-46af-a4a6-098d75755e50",
   "metadata": {},
   "source": [
    "###  STEP  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed942267-553a-4677-a1e2-a80b73a971a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr: [1 0 0 ... 0 0 0]\n",
      "and: [0 1 0 ... 0 0 0]\n",
      "mrs: [0 0 1 ... 0 0 0]\n",
      "dursley: [0 0 0 ... 0 0 0]\n",
      "of: [0 0 0 ... 0 0 0]\n",
      "number: [0 0 0 ... 0 0 0]\n",
      "four: [0 0 0 ... 0 0 0]\n",
      "privet: [0 0 0 ... 0 0 0]\n",
      "drive: [0 0 0 ... 0 0 0]\n",
      "were: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have vocab and word_to_index from earlier in your code\n",
    "vocab_size = len(tokens)\n",
    "\n",
    "# Print one-hot\n",
    "for i, word in enumerate(vocabulary[:10]):\n",
    "    one_hot_vector = np.zeros(vocab_size, dtype=int)\n",
    "    one_hot_vector[i] = 1\n",
    "    print(f\"{word}: {one_hot_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f3f5e-88e6-4387-a4fc-b2d3b6febd7e",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e51b386-7a50-4321-82e7-68865595abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs (focal_word -> context_word):\n",
      "\n",
      "First 5 pairs only:\n",
      "mr (0) -> and (1)\n",
      "mr (0) -> mrs (2)\n",
      "and (1) -> mr (0)\n",
      "and (1) -> mrs (2)\n",
      "and (1) -> dursley (3)\n",
      "mrs (2) -> mr (0)\n",
      "mrs (2) -> and (1)\n",
      "mrs (2) -> dursley (3)\n",
      "mrs (2) -> of (4)\n",
      "dursley (3) -> and (1)\n"
     ]
    }
   ],
   "source": [
    "training_pairs = []\n",
    "\n",
    "for i, focal_word in enumerate(tokens):\n",
    "    # Define context window indices\n",
    "    start = max(0, i - CONTEXT_WINDOW_SIZE)\n",
    "    end = min(len(tokens), i + CONTEXT_WINDOW_SIZE + 1)\n",
    "    \n",
    "    for j in range(start, end):\n",
    "        if i == j:\n",
    "            continue  # skip the focal word itself\n",
    "        \n",
    "        context_word = tokens[j]\n",
    "        training_pairs.append((word_to_idx[focal_word], word_to_idx[context_word]))\n",
    "\n",
    "# Print pairs with words for clarity\n",
    "print(\"Training pairs (focal_word -> context_word):\")\n",
    "print(\"\\nFirst 5 pairs only:\")\n",
    "for focal_idx, context_idx in training_pairs[:10]:\n",
    "    print(f\"{tokens[focal_idx]} ({focal_idx}) -> {tokens[context_idx]} ({context_idx})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ecb977-f020-42ff-9fed-202d55dd0498",
   "metadata": {},
   "source": [
    "### STEP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00470c5-090d-424a-82b8-7054cad1639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 8.3031\n",
      "Epoch [2/100], Loss: 7.7161\n",
      "Epoch [3/100], Loss: 7.4201\n",
      "Epoch [4/100], Loss: 7.2602\n",
      "Epoch [5/100], Loss: 7.1575\n",
      "Epoch [6/100], Loss: 7.0826\n",
      "Epoch [7/100], Loss: 7.0230\n",
      "Epoch [8/100], Loss: 6.9739\n",
      "Epoch [9/100], Loss: 6.9323\n",
      "Epoch [10/100], Loss: 6.8967\n",
      "Epoch [11/100], Loss: 6.8657\n",
      "Epoch [12/100], Loss: 6.8383\n",
      "Epoch [13/100], Loss: 6.8140\n",
      "Epoch [14/100], Loss: 6.7919\n",
      "Epoch [15/100], Loss: 6.7717\n",
      "Epoch [16/100], Loss: 6.7532\n",
      "Epoch [17/100], Loss: 6.7358\n",
      "Epoch [18/100], Loss: 6.7198\n",
      "Epoch [19/100], Loss: 6.7046\n",
      "Epoch [20/100], Loss: 6.6904\n",
      "Epoch [21/100], Loss: 6.6771\n",
      "Epoch [22/100], Loss: 6.6644\n",
      "Epoch [23/100], Loss: 6.6527\n",
      "Epoch [24/100], Loss: 6.6414\n",
      "Epoch [25/100], Loss: 6.6308\n",
      "Epoch [26/100], Loss: 6.6208\n",
      "Epoch [27/100], Loss: 6.6113\n",
      "Epoch [28/100], Loss: 6.6022\n",
      "Epoch [29/100], Loss: 6.5937\n",
      "Epoch [30/100], Loss: 6.5855\n",
      "Epoch [31/100], Loss: 6.5779\n",
      "Epoch [32/100], Loss: 6.5705\n",
      "Epoch [33/100], Loss: 6.5635\n",
      "Epoch [34/100], Loss: 6.5568\n",
      "Epoch [35/100], Loss: 6.5503\n",
      "Epoch [36/100], Loss: 6.5442\n",
      "Epoch [37/100], Loss: 6.5383\n",
      "Epoch [38/100], Loss: 6.5326\n",
      "Epoch [39/100], Loss: 6.5272\n",
      "Epoch [40/100], Loss: 6.5219\n",
      "Epoch [41/100], Loss: 6.5169\n",
      "Epoch [42/100], Loss: 6.5120\n",
      "Epoch [43/100], Loss: 6.5072\n",
      "Epoch [44/100], Loss: 6.5027\n",
      "Epoch [45/100], Loss: 6.4984\n",
      "Epoch [46/100], Loss: 6.4940\n",
      "Epoch [47/100], Loss: 6.4899\n",
      "Epoch [48/100], Loss: 6.4859\n",
      "Epoch [49/100], Loss: 6.4819\n",
      "Epoch [50/100], Loss: 6.4782\n",
      "Epoch [51/100], Loss: 6.4745\n",
      "Epoch [52/100], Loss: 6.4709\n",
      "Epoch [53/100], Loss: 6.4674\n",
      "Epoch [54/100], Loss: 6.4640\n",
      "Epoch [55/100], Loss: 6.4608\n",
      "Epoch [56/100], Loss: 6.4576\n",
      "Epoch [57/100], Loss: 6.4545\n",
      "Epoch [58/100], Loss: 6.4514\n",
      "Epoch [59/100], Loss: 6.4485\n",
      "Epoch [60/100], Loss: 6.4456\n",
      "Epoch [61/100], Loss: 6.4427\n",
      "Epoch [62/100], Loss: 6.4398\n",
      "Epoch [63/100], Loss: 6.4372\n",
      "Epoch [64/100], Loss: 6.4345\n",
      "Epoch [65/100], Loss: 6.4319\n",
      "Epoch [66/100], Loss: 6.4294\n",
      "Epoch [67/100], Loss: 6.4269\n",
      "Epoch [68/100], Loss: 6.4244\n",
      "Epoch [69/100], Loss: 6.4220\n",
      "Epoch [70/100], Loss: 6.4197\n",
      "Epoch [71/100], Loss: 6.4174\n",
      "Epoch [72/100], Loss: 6.4151\n",
      "Epoch [73/100], Loss: 6.4129\n",
      "Epoch [74/100], Loss: 6.4107\n",
      "Epoch [75/100], Loss: 6.4087\n",
      "Epoch [76/100], Loss: 6.4065\n",
      "Epoch [77/100], Loss: 6.4045\n",
      "Epoch [78/100], Loss: 6.4025\n",
      "Epoch [79/100], Loss: 6.4005\n",
      "Epoch [80/100], Loss: 6.3986\n",
      "Epoch [81/100], Loss: 6.3967\n",
      "Epoch [82/100], Loss: 6.3948\n",
      "Epoch [83/100], Loss: 6.3930\n",
      "Epoch [84/100], Loss: 6.3913\n",
      "Epoch [85/100], Loss: 6.3895\n",
      "Epoch [86/100], Loss: 6.3877\n",
      "Epoch [87/100], Loss: 6.3861\n",
      "Epoch [88/100], Loss: 6.3844\n",
      "Epoch [89/100], Loss: 6.3828\n",
      "Epoch [90/100], Loss: 6.3812\n",
      "Epoch [91/100], Loss: 6.3796\n",
      "Epoch [92/100], Loss: 6.3781\n",
      "Epoch [93/100], Loss: 6.3765\n",
      "Epoch [94/100], Loss: 6.3750\n",
      "Epoch [95/100], Loss: 6.3735\n",
      "Epoch [96/100], Loss: 6.3720\n",
      "Epoch [97/100], Loss: 6.3706\n",
      "Epoch [98/100], Loss: 6.3692\n",
      "Epoch [99/100], Loss: 6.3678\n",
      "Epoch [100/100], Loss: 6.3664\n",
      "\n",
      "Word embeddings shape: torch.Size([6022, 10])\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 10\n",
    "vocab_size = len(vocabulary)\n",
    "epochs = 100\n",
    "learning_rate = 0.1\n",
    "init_std = 0.05\n",
    "batch_size = 256  # small batches to avoid memory issues\n",
    "\n",
    "# Convert training pairs to tensors\n",
    "X_train = torch.tensor([center for center, _ in training_pairs], dtype=torch.long)\n",
    "y_train = torch.tensor([context for _, context in training_pairs], dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for mini-batch training\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Skip-gram model\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, init_std):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.output = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        # Small Gaussian initialization\n",
    "        nn.init.normal_(self.embeddings.weight, mean=0.0, std=init_std)\n",
    "        nn.init.normal_(self.output.weight, mean=0.0, std=init_std)\n",
    "        nn.init.zeros_(self.output.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)   # (batch, embed_dim)\n",
    "        x = self.output(x)       # (batch, vocab_size)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = SkipGramModel(vocab_size, embedding_dim, init_std)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop with mini-batches\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Extract learned embeddings\n",
    "word_embeddings = model.embeddings.weight.data\n",
    "print(\"\\nWord embeddings shape:\", word_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d16d29-58cf-4f9a-89a6-df2077f72a11",
   "metadata": {},
   "source": [
    "# STEP 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca01f1d8-3628-4bc1-8f34-807c39f5b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot vector for 'harry':\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "\n",
      "Embedding vector for 'harry':\n",
      "tensor([ 0.9439, -0.8520,  0.5920,  1.1341, -0.3767, -0.5537,  0.2148, -0.1261,\n",
      "        -0.1760, -1.7613], grad_fn=<SqueezeBackward0>)\n",
      "\n",
      "One-hot vector for 'and':\n",
      "tensor([0., 1., 0.,  ..., 0., 0., 0.])\n",
      "\n",
      "Embedding vector for 'and':\n",
      "tensor([-0.2036, -1.2905,  0.8329,  0.3956, -0.6224, -0.4276,  0.5420,  0.3732,\n",
      "         0.6058, -0.4890], grad_fn=<SqueezeBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def word_to_one_hot(word, word_to_idx):\n",
    "    vocab_size = len(word_to_idx)\n",
    "    one_hot = torch.zeros(vocab_size)\n",
    "    idx = word_to_idx.get(word)\n",
    "    if idx is None:\n",
    "        raise ValueError(f\"Word '{word}' not found in vocabulary.\")\n",
    "    one_hot[idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "def get_embedding_from_word(model, word, word_to_idx):\n",
    "    word_index = word_to_idx[word]\n",
    "    embedding = model.embeddings(torch.tensor([word_index]))\n",
    "    return embedding.squeeze()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter a word (or 'quit' to stop): \").strip()\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        one_hot_vector = word_to_one_hot(user_input, word_to_idx)\n",
    "        print(f\"One-hot vector for '{user_input}':\\n{one_hot_vector}\\n\")\n",
    "        \n",
    "        embedding_vector = get_embedding_from_word(model, user_input, word_to_idx)\n",
    "        print(f\"Embedding vector for '{user_input}':\\n{embedding_vector}\\n\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b3162d-103c-4521-98ff-29994ab91ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'quit' not found in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Disable truncation for printing tensors\n",
    "torch.set_printoptions(threshold=10_000)  # set very high threshold to print full tensor\n",
    "\n",
    "user_input = input(\"Enter a word (or 'quit' to stop): \").strip()\n",
    "\n",
    "try:\n",
    "    one_hot_vector = word_to_one_hot(user_input, word_to_idx)\n",
    "    print(f\"One-hot vector for '{user_input}':\\n{one_hot_vector}\\n\")\n",
    "        \n",
    "    embedding_vector = get_embedding_from_word(model, user_input, word_to_idx)\n",
    "    print(f\"Embedding vector for '{user_input}':\\n{embedding_vector}\\n\")\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacdd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99f9fc15",
   "metadata": {},
   "source": [
    "# Implementing a mapping between corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f2ccd8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_embeddings_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ensure your embedding tensors are on the CPU and converted to NumPy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m embeddings_A = \u001b[43mword_embeddings_1\u001b[49m.cpu().numpy()\n\u001b[32m      3\u001b[39m embeddings_B = word_embeddings_2.cpu().numpy()\n\u001b[32m      4\u001b[39m word_to_idx_A = word_to_idx_1\n",
      "\u001b[31mNameError\u001b[39m: name 'word_embeddings_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure your embedding tensors are on the CPU and converted to NumPy\n",
    "embeddings_A = word_embeddings_1.cpu().numpy()\n",
    "embeddings_B = word_embeddings_2.cpu().numpy()\n",
    "word_to_idx_A = word_to_idx_1\n",
    "word_to_idx_B = word_to_idx_2\n",
    "\n",
    "# 1. Find the shared vocabulary\n",
    "vocab_A = set(word_to_idx_A.keys())\n",
    "vocab_B = set(word_to_idx_B.keys())\n",
    "shared_vocab = sorted(list(vocab_A.intersection(vocab_B)))\n",
    "\n",
    "print(f\"Found {len(shared_vocab)} shared words between the two vocabularies.\")\n",
    "\n",
    "# 2. Create alignment matrices for the shared words\n",
    "# These will hold the embeddings for the words that exist in BOTH texts.\n",
    "X_A = np.zeros((len(shared_vocab), embeddings_A.shape[1]))\n",
    "X_B = np.zeros((len(shared_vocab), embeddings_B.shape[1]))\n",
    "\n",
    "for i, word in enumerate(shared_vocab):\n",
    "    idx_A = word_to_idx_A[word]\n",
    "    idx_B = word_to_idx_B[word]\n",
    "    \n",
    "    X_A[i] = embeddings_A[idx_A]\n",
    "    X_B[i] = embeddings_B[idx_B]\n",
    "\n",
    "# 3. Solve for the transformation matrix T using the pseudo-inverse\n",
    "# This finds the optimal linear map T such that X_A @ T is as close as possible to X_B\n",
    "T = np.linalg.pinv(X_A) @ X_B\n",
    "\n",
    "print(f\"Learned transformation matrix T with shape: {T.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281239f9-0390-48a4-9004-486b3215e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Phase 3: Evaluate the Mapping\n",
    "\n",
    "# 1. Transform the embedding space A using the learned matrix T\n",
    "mapped_X_A = X_A @ T\n",
    "\n",
    "# 2. Calculate the cosine similarity for each word pair\n",
    "# We will compare each mapped vector from A with its corresponding true vector in B\n",
    "dot_products = np.sum(mapped_X_A * X_B, axis=1)\n",
    "norms_A = np.linalg.norm(mapped_X_A, axis=1)\n",
    "norms_B = np.linalg.norm(X_B, axis=1)\n",
    "\n",
    "# To avoid division by zero for any potential zero-vectors\n",
    "valid_indices = (norms_A > 0) & (norms_B > 0)\n",
    "similarities = dot_products[valid_indices] / (norms_A[valid_indices] * norms_B[valid_indices])\n",
    "\n",
    "# 3. Display the results\n",
    "average_similarity = np.mean(similarities)\n",
    "print(f\"--- Evaluation Results ---\")\n",
    "print(f\"Average Cosine Similarity between mapped and target vectors: {average_similarity:.4f}\")\n",
    "\n",
    "# 4. Show some examples for qualitative analysis\n",
    "print(\"\\n--- Example Word-level Similarities ---\")\n",
    "for i in range(10): # Print the similarity for the first 10 shared words\n",
    "    word = shared_vocab[i]\n",
    "    similarity = similarities[i]\n",
    "    print(f\"Word: '{word}', Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2c40a-4695-42a1-8b14-f12e0a6b710c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ec400af-758f-4b31-9d1e-de15ffb9fdd3",
   "metadata": {},
   "source": [
    "### Can we map from one embedding space to another where the embeddings are trained on different data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948ad56-d4d7-49e9-9a0c-9fd22866e56d",
   "metadata": {},
   "source": [
    "Yes, you can map one embedding space to another even if they are trained on different data — this is a well-studied problem in NLP and related fields.\n",
    "\n",
    "Why do this?\n",
    "Different embedding models (e.g., trained on different corpora, languages, or time periods) live in different vector spaces.\n",
    "\n",
    "Mapping between spaces enables alignment, transfer learning, or cross-lingual embeddings.\n",
    "\n",
    "Common approaches\n",
    "Learn a linear transformation (mapping matrix) W:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cf5a1-ec80-4fda-908b-a1a3c7b05c25",
   "metadata": {},
   "source": [
    "from target (for a shared vocabulary or dictionary), find matrix 𝑊 that minimizes:\n",
    "Usually solved by Procrustes analysis or orthogonal Procrustes if you constrain \n",
    "𝑊 to be orthogonal.\n",
    "\n",
    "Requires a bilingual dictionary or anchor points (shared words) to align.\n",
    "\n",
    "Non-linear mappings:\n",
    "\n",
    "Use neural networks (MLPs) to learn more complex mappings.\n",
    "\n",
    "Often less common for basic embedding alignment but helpful for very different domains.\n",
    "\n",
    "Iterative refinement:\n",
    "\n",
    "Start with a seed dictionary, learn 𝑊.\n",
    "\n",
    "Use 𝑊 to find more pairs, retrain \n",
    "𝑊, repeat.\n",
    "\n",
    "Practical example:\n",
    "Mapping GloVe embeddings trained on Wikipedia to fastText embeddings trained on Common Crawl.\n",
    "\n",
    "Cross-lingual embeddings to translate embeddings between languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584e46b-2dc3-4a48-8fe3-9e49f9153b3d",
   "metadata": {},
   "source": [
    " it's common and practical — with enough shared words or anchor points, you can effectively align and map embedding spaces trained on different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9655f30-285e-4097-a239-db8cd978772d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920159c-cfcb-473e-86cb-72a492fa26e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b105553-d551-44a9-a0ee-d8c6476c0e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5791750-0ef7-4bef-90a7-0048fd340b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
